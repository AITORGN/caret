
    
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
  <!--
  Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Emerald 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20120902

-->
  <html xmlns="http://www.w3.org/1999/xhtml">
  <head>
<style type="text/css">.knitr.inline {
  background-color: #f7f7f7;
  border:solid 1px #B0B0B0;
}
.error {
  font-weight: bold;
	color: #FF0000;
},
.warning {
	font-weight: bold;
}
.message {
	font-style: italic;
}
.source, .output, .warning, .error, .message {
	padding: 0em 1em;
  border:solid 1px #F7F7F7;
}
.source {
  background-color: #f5f5f5;
}
.rimage.left {
  text-align: left;
}
.rimage.right {
  text-align: right;
}
.rimage.center {
  text-align: center;
}
.hl.num {
  color: #AF0F91;
}
.hl.str {
  color: #317ECC;
}
.hl.com {
  color: #AD95AF;
  font-style: italic;
}
.hl.opt {
  color: #000000;
}
.hl.std {
  color: #585858;
}
.hl.kwa {
  color: #295F94;
  font-weight: bold;
}
.hl.kwb {
  color: #B05A65;
}
.hl.kwc {
  color: #55aa55;
}
.hl.kwd {
  color: #BC5A65;
  font-weight: bold;
}</style>
  <meta name="keywords" content="" />
  <meta name="description" content="" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <title>Implicit Feature Selection Models</title>
  <link href='http://fonts.googleapis.com/css?family=Abel' rel='stylesheet' type='text/css'>
  <link href="style.css" rel="stylesheet" type="text/css" media="screen" />
  </head>
  <body>
  <div id="wrapper">
  <div id="header-wrapper" class="container">
  <div id="header" class="container">
  <div id="logo">
  <h1><a href="#">Implicit Feature Selection Models</a></h1>
</div>
  <!--
  <div id="menu">
  <ul>
  <li class="current_page_item"><a href="#">Homepage</a></li>
<li><a href="#">Blog</a></li>
<li><a href="#">Photos</a></li>
<li><a href="#">About</a></li>
<li><a href="#">Contact</a></li>
</ul>
  </div>
  -->
  </div>
  <div><img src="images/img03.png" width="1000" height="40" alt="" /></div>
  </div>
  <!-- end #header -->
<div id="page">
  <div id="content">
  
<h1>AdaBoost Classification Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'adaboost'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nIter</span></code> (#Trees), <code><span class="mx arg">method</span></code> (Method)</p>

<h1>AdaBoost.M1</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'AdaBoost.M1'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mfinal</span></code> (#Trees), <code><span class="mx arg">maxdepth</span></code> (Max Tree Depth), <code><span class="mx arg">coeflearn</span></code> (Coefficient Type)</p>

<h1>Bagged AdaBoost</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'AdaBag'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mfinal</span></code> (#Trees), <code><span class="mx arg">maxdepth</span></code> (Max Tree Depth)</p>

<h1>Bagged Flexible Discriminant Analysis</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'bagFDA'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">degree</span></code> (Product Degree), <code><span class="mx arg">nprune</span></code> (#Terms)</p>

<h1>Bagged MARS</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'bagEarth'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nprune</span></code> (#Terms), <code><span class="mx arg">degree</span></code> (Product Degree)</p>

<h1>Bagged MARS using gCV Pruning</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'bagEarthGCV'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">degree</span></code> (Product Degree)</p>

<h1>Bayesian Additive Regression Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'bartMachine'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">num_trees</span></code> (#Trees), <code><span class="mx arg">k</span></code> (Prior Boundary), <code><span class="mx arg">alpha</span></code> (Base Terminal Node Hyperparameter), <code><span class="mx arg">beta</span></code> (Power Terminal Node Hyperparameter), <code><span class="mx arg">nu</span></code> (Degrees of Freedom)</p>

<h1>Boosted Classification Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ada'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">iter</span></code> (#Trees), <code><span class="mx arg">maxdepth</span></code> (Max Tree Depth), <code><span class="mx arg">nu</span></code> (Learning Rate)</p>

<h1>Boosted Generalized Additive Model</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'gamboost'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mstop</span></code> (# Boosting Iterations), <code><span class="mx arg">prune</span></code> (AIC Prune?)</p>

<h1>Boosted Linear Model</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'BstLm'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mstop</span></code> (# Boosting Iterations), <code><span class="mx arg">nu</span></code> (Shrinkage)</p>

<h1>Boosted Logistic Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'LogitBoost'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nIter</span></code> (# Boosting Iterations)</p>

<h1>Boosted Smoothing Spline</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'bstSm'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mstop</span></code> (# Boosting Iterations), <code><span class="mx arg">nu</span></code> (Shrinkage)</p>

<h1>C4.5-like Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'J48'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">C</span></code> (Confidence Threshold)</p>

<h1>C5.0</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'C5.0'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">trials</span></code> (# Boosting Iterations), <code><span class="mx arg">model</span></code> (Model Type), <code><span class="mx arg">winnow</span></code> (Winnow)</p>

<h1>CART</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rpart'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">cp</span></code> (Complexity Parameter)</p>

<h1>CART</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rpart1SE'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p>No Tuning Parameters</p>

<h1>CART</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rpart2'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">maxdepth</span></code> (Max Tree Depth)</p>

<h1>CHi-squared Automated Interaction Detection</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'chaid'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">alpha2</span></code> (Merging Threshold), <code><span class="mx arg">alpha3</span></code> (Splitting former Merged Threshold), <code><span class="mx arg">alpha4</span></code> (
                                                    Splitting former Merged Threshold)</p>

<h1>Conditional Inference Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'cforest'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Conditional Inference Tree</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ctree'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mincriterion</span></code> (1 - P-Value Threshold)</p>

<h1>Conditional Inference Tree</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ctree2'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">maxdepth</span></code> (Max Tree Depth)</p>

<h1>Cost-Sensitive C5.0</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'C5.0Cost'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">trials</span></code> (# Boosting Iterations), <code><span class="mx arg">model</span></code> (Model Type), <code><span class="mx arg">winnow</span></code> (Winnow), <code><span class="mx arg">cost</span></code> (Cost)</p>

<h1>Cost-Sensitive CART</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rpartCost'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">cp</span></code> (Complexity Parameter), <code><span class="mx arg">Cost</span></code> (Cost)</p>

<h1>Cubist</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'cubist'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">committees</span></code> (#Committees), <code><span class="mx arg">neighbors</span></code> (#Instances)</p>

<h1>DeepBoost</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'deepboost'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">num_iter</span></code> (# Boosting Iterations), <code><span class="mx arg">tree_depth</span></code> (Tree Depth), <code><span class="mx arg">beta</span></code> (L1 Regularization), <code><span class="mx arg">lambda</span></code> (Tree Depth Regularization), <code><span class="mx arg">loss_type</span></code> (Loss)</p>

<h1>Elasticnet</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'enet'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">fraction</span></code> (Fraction of Full Solution), <code><span class="mx arg">lambda</span></code> (Weight Decay)</p>

<h1>eXtreme Gradient Boosting</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'xgbLinear'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nrounds</span></code> (# Boosting Iterations), <code><span class="mx arg">lambda</span></code> (L2 Regularization), <code><span class="mx arg">alpha</span></code> (L1 Regularization), <code><span class="mx arg">eta</span></code> (Learning Rate)</p>

<h1>eXtreme Gradient Boosting</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'xgbTree'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nrounds</span></code> (# Boosting Iterations), <code><span class="mx arg">max_depth</span></code> (Max Tree Depth), <code><span class="mx arg">eta</span></code> (Shrinkage), <code><span class="mx arg">gamma</span></code> (Minimum Loss Reduction), <code><span class="mx arg">colsample_bytree</span></code> (Subsample Ratio of Columns), <code><span class="mx arg">min_child_weight</span></code> (Minimum Sum of Instance Weight)</p>

<h1>Flexible Discriminant Analysis</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'fda'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">degree</span></code> (Product Degree), <code><span class="mx arg">nprune</span></code> (#Terms)</p>

<h1>Generalized Linear Model with Stepwise Feature Selection</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'glmStepAIC'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p>No Tuning Parameters</p>

<h1>glmnet</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'glmnet'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">alpha</span></code> (Mixing Percentage), <code><span class="mx arg">lambda</span></code> (Regularization Parameter)</p>

<h1>Least Angle Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'lars'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">fraction</span></code> (Fraction)</p>

<h1>Least Angle Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'lars2'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">step</span></code> (#Steps)</p>

<h1>Logistic Model Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'LMT'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">iter</span></code> (# Iteratons)</p>

<h1>Model Rules</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'M5Rules'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">pruned</span></code> (Pruned), <code><span class="mx arg">smoothed</span></code> (Smoothed)</p>

<h1>Model Tree</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'M5'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">pruned</span></code> (Pruned), <code><span class="mx arg">smoothed</span></code> (Smoothed), <code><span class="mx arg">rules</span></code> (Rules)</p>

<h1>Multivariate Adaptive Regression Spline</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'earth'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">nprune</span></code> (#Terms), <code><span class="mx arg">degree</span></code> (Product Degree)</p>

<h1>Multivariate Adaptive Regression Splines</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'gcvEarth'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">degree</span></code> (Product Degree)</p>

<h1>Nearest Shrunken Centroids</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'pam'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">threshold</span></code> (Shrinkage Threshold)</p>

<h1>Non-Convex Penalized Quantile Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rqnc'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda</span></code> (L1 Penalty), <code><span class="mx arg">penalty</span></code> (Penalty Type)</p>

<h1>Oblique Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ORFlog'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Oblique Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ORFpls'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Oblique Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ORFridge'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Oblique Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ORFsvm'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Oblique Trees</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'oblique.tree'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">oblique.splits</span></code> (Oblique Splits), <code><span class="mx arg">variable.selection</span></code> (Variable Selection Method)</p>

<h1>Parallel Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'parRF'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Penalized Linear Discriminant Analysis</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'PenalizedLDA'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda</span></code> (L1 Penalty), <code><span class="mx arg">K</span></code> (#Discriminant Functions)</p>

<h1>Penalized Linear Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'penalized'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda1</span></code> (L1 Penalty), <code><span class="mx arg">lambda2</span></code> (L2 Penalty)</p>

<h1>Quantile Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'qrf'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Quantile Regression with LASSO penalty</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rqlasso'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda</span></code> (L1 Penalty)</p>

<h1>Random Ferns</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rFerns'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">depth</span></code> (Fern Depth)</p>

<h1>Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'ranger'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rf'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>

<h1>Random Forest by Randomization</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'extraTrees'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (# Randomly Selected Predictors), <code><span class="mx arg">numRandomCuts</span></code> (# Random Cuts)</p>

<h1>Random Forest Rule-Based Model</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rfRules'</span></tt></p>
<p><b>Type</b>: Classification, Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors), <code><span class="mx arg">maxdepth</span></code> (Maximum Rule Depth)</p>

<h1>Regularized Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'RRF'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors), <code><span class="mx arg">coefReg</span></code> (Regularization Value), <code><span class="mx arg">coefImp</span></code> (Importance Coefficient)</p>

<h1>Regularized Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'RRFglobal'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors), <code><span class="mx arg">coefReg</span></code> (Regularization Value)</p>

<h1>Relaxed Lasso</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'relaxo'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda</span></code> (Penalty Parameter), <code><span class="mx arg">phi</span></code> (Relaxation Parameter)</p>

<h1>Rotation Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rotationForest'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">K</span></code> (#Variable Subsets), <code><span class="mx arg">L</span></code> (Ensemble Size)</p>

<h1>Rotation Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'rotationForestCp'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">K</span></code> (#Variable Subsets), <code><span class="mx arg">L</span></code> (Ensemble Size), <code><span class="mx arg">cp</span></code> (Complexity Parameter)</p>

<h1>Rule-Based Classifier</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'JRip'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">NumOpt</span></code> (# Optimizations)</p>

<h1>Rule-Based Classifier</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'PART'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">threshold</span></code> (Confidence Threshold), <code><span class="mx arg">pruned</span></code> (Confidence Threshold)</p>

<h1>Single C5.0 Ruleset</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'C5.0Rules'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p>No Tuning Parameters</p>

<h1>Single C5.0 Tree</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'C5.0Tree'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p>No Tuning Parameters</p>

<h1>Single Rule Classification</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'OneR'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p>No Tuning Parameters</p>

<h1>Sparse Distance Weighted Discrimination</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'sdwd'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">lambda</span></code> (L1 Penalty), <code><span class="mx arg">lambda2</span></code> (L2 Penalty)</p>

<h1>Sparse Linear Discriminant Analysis</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'sparseLDA'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">NumVars</span></code> (# Predictors), <code><span class="mx arg">lambda</span></code> (Lambda)</p>

<h1>Sparse Mixture Discriminant Analysis</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'smda'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">NumVars</span></code> (# Predictors), <code><span class="mx arg">lambda</span></code> (Lambda), <code><span class="mx arg">R</span></code> (# Subclasses)</p>

<h1>Spike and Slab Regression</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'spikeslab'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">vars</span></code> (Variables Retained)</p>

<h1>Stochastic Gradient Boosting</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'gbm'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">n.trees</span></code> (# Boosting Iterations), <code><span class="mx arg">interaction.depth</span></code> (Max Tree Depth), <code><span class="mx arg">shrinkage</span></code> (Shrinkage), <code><span class="mx arg">n.minobsinnode</span></code> (Min. Terminal Node Size)</p>

<h1>The Bayesian lasso</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'blasso'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">sparsity</span></code> (Sparsity Threshold)</p>

<h1>The lasso</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'lasso'</span></tt></p>
<p><b>Type</b>: Regression</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">fraction</span></code> (Fraction of Full Solution)</p>

<h1>Tree Models from Genetic Algorithms</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'evtree'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">alpha</span></code> (Complexity Parameter)</p>

<h1>Tree-Based Ensembles</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'nodeHarvest'</span></tt></p>
<p><b>Type</b>: Regression, Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">maxinter</span></code> (Maximum Interaction Depth), <code><span class="mx arg">mode</span></code> (Prediction Mode)</p>

<h1>Weighted Subspace Random Forest</h1>
<p><tt><span class="mx arg">method</span> = <span class="mx str">'wsrf'</span></tt></p>
<p><b>Type</b>: Classification</p>
<p><b>Tuning Parameters</b>: <code><span class="mx arg">mtry</span></code> (#Randomly Selected Predictors)</p>


<div style="clear: both;">&nbsp;</div>
  </div>
  <!-- end #content -->
<div id="sidebar">
<ul>
  <li>
    <h2>General Topics</h2>
    <ul>
      <li><a href="index.html">Front Page</a></li>
      <li><a href="visualizations.html">Visualizations</a></li>
      <li><a href="preprocess.html">Pre-Processing</a><li>
      <li><a href="splitting.html">Data Splitting</a></li>
      <li><a href="varimp.html">Variable Importance</a></li>
      <li><a href="parallel.html">Parallel Processing</a></li>
    </ul>
    <h2>Model Training and Tuning</h2>
    <ul>
      <li><a href="training.html">Basic Syntax</a></li>
      <li><a href="modelList.html">Sortable Model List</a></li>
      <li><a href="bytag.html">Models By Tag</a></li>
      <li><a href="similarity.html">Models By Similarity</a></li>
      <li><a href="custom_models.html">Using Custom Models</a></li>
      <li><a href="sampling.html">Sampling for Class Imbalances</a></li> 
      <li><a href="random.html">Random Search</a></li> 
      <li><a href="adaptive.html">Adaptive Resampling</a></li> 
    </ul>
    <h2>Feature Selection</h2>
    <ul>
      <li><a href="featureselection.html">Overview</a>
      <li><a href="rfe.html">RFE</a></li>
      <li><a href="filters.html">Filters</a></li>
      <li><a href="GA.html">GA</a></li>
      <li><a href="SA.html">SA</a></li>
    </ul>  
  </li>
</ul>
</div>
<!-- end #sidebar -->
<div style="clear: both;">&nbsp;</div>
  </div>
  <div class="container"><img src="images/img03.png" width="1000" height="40" alt="" /></div>
  <!-- end #page -->
</div>
  <div id="footer-content"></div>
  <div id="footer">
  <p>Created on Sun Apr 10 2016 using caret version 6.0-68 and R Under development (unstable) (2016-04-08 r70447).</p>
  </div>
  <!-- end #footer -->
</body>
  </html>