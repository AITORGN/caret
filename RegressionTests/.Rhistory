set.seed(2)
i_set_rand_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 15,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds)
library(doMC)
registerDoMC(cores=6)
set.seed(2)
i_set_par_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
save(let_set_64, i_set_64, i_set_par_64, i_set_rand_64, file = "~/tmp/caret_6.0-64.RData")
#
#
# plot_both <- function(older, newer) {
#   older$results$when <- "old"
#   newer$results$when <- "new"
#   plot_dat <- rbind(newer$results, older$results)
#   ggplot(plot_dat, aes(x = C, y = RMSE, color = when)) +
#     geom_point() + geom_line() + theme_bw()
#
# }
ggplot(i_set_par_64)
ggplot(i_set_64)
library(caret)
set.seed(1)
dat <- SLC14_1(1000)
ctrl <- trainControl(method = "cv")
set.seed(2)
let_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
set.seed(3)
seeds <- vector(mode = "list", length = length(let_set_64$control$index) + 1)
seeds <- lapply(seeds, function(x) sample.int(1000, 50))
ctrl <- trainControl(method = "cv", seeds = seeds)
set.seed(2)
i_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds, search = "random")
set.seed(2)
i_set_rand_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 15,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds)
library(doMC)
registerDoMC(cores=6)
set.seed(2)
i_set_par_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
save(let_set_64, i_set_64, i_set_par_64, i_set_rand_64, file = "~/tmp/caret_6.0-66.RData")
#
#
# plot_both <- function(older, newer) {
#   older$results$when <- "old"
#   newer$results$when <- "new"
#   plot_dat <- rbind(newer$results, older$results)
#   ggplot(plot_dat, aes(x = C, y = RMSE, color = when)) +
#     geom_point() + geom_line() + theme_bw()
#
# }
load("~/tmp/caret_6.0-64.RData")
load("~/tmp/caret_6.0-66.RData")
ls()
library(caret)
set.seed(1)
dat <- SLC14_1(1000)
ctrl <- trainControl(method = "cv")
set.seed(2)
let_set_66 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
set.seed(3)
seeds <- vector(mode = "list", length = length(let_set_66$control$index) + 1)
seeds <- lapply(seeds, function(x) sample.int(1000, 50))
ctrl <- trainControl(method = "cv", seeds = seeds)
set.seed(2)
i_set_66 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds, search = "random")
set.seed(2)
i_set_rand_66 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 15,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds)
library(doMC)
registerDoMC(cores=6)
set.seed(2)
i_set_par_66 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
save(let_set_66, i_set_66, i_set_par_66, i_set_rand_66, file = "~/tmp/caret_6.0-66.RData")
#
#
# plot_both <- function(older, newer) {
#   older$results$when <- "old"
#   newer$results$when <- "new"
#   plot_dat <- rbind(newer$results, older$results)
#   ggplot(plot_dat, aes(x = C, y = RMSE, color = when)) +
#     geom_point() + geom_line() + theme_bw()
#
# }
library(caret)
set.seed(1)
dat <- SLC14_1(1000)
ctrl <- trainControl(method = "cv")
set.seed(2)
let_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
set.seed(3)
seeds <- vector(mode = "list", length = length(let_set_64$control$index) + 1)
seeds <- lapply(seeds, function(x) sample.int(1000, 50))
ctrl <- trainControl(method = "cv", seeds = seeds)
set.seed(2)
i_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds, search = "random")
set.seed(2)
i_set_rand_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 15,
trControl = ctrl)
ctrl <- trainControl(method = "cv", seeds = seeds)
library(doMC)
registerDoMC(cores=6)
set.seed(2)
i_set_par_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
save(let_set_64, i_set_64, i_set_par_64, i_set_rand_64, file = "~/tmp/caret_6.0-64.RData")
#
#
# plot_both <- function(older, newer) {
#   older$results$when <- "old"
#   newer$results$when <- "new"
#   plot_dat <- rbind(newer$results, older$results)
#   ggplot(plot_dat, aes(x = C, y = RMSE, color = when)) +
#     geom_point() + geom_line() + theme_bw()
#
# }
load("~/tmp/caret_6.0-64.RData")
load("~/tmp/caret_6.0-66.RData")
ls()
ggplot(i_set_64)
library(caret)
ggplot(i_set_64)
ggplot(i_set_66)
all.equal(i_set_64$results, i_set_66$results)
all.equal(i_set_par_64$results, i_set_66$results)
ggplot(i_set_rand_64)
ggplot(i_set_rand_66)
ggplot(let_set_64)
ggplot(let_set_66)
all.equal(let_set_64$control$index, let_set_66$control$index)
library(caret)
set.seed(1)
dat <- SLC14_1(1000)
ctrl <- trainControl(method = "apparent")
set.seed(2)
let_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
ggplot(let_set_64)
let_set_64
ctrl <- trainControl(method = "cv")
set.seed(2)
let_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
ggplot(let_set_64)
ctrl <- trainControl(method = "cv", savePredictions = "all")
set.seed(2)
let_set_64 <- train(y ~ ., data = dat, method = "nnet",
preProc = c("center", "scale"),
linout = TRUE, trace = FALSE,
tuneLength = 5,
trControl = ctrl)
foo <- function(x) {
rs <- x$resamples
rs <- merge(rs, x$bestTune)
rs
}
foo(let_set_64)
let_set_64
let_set_64$resample
foo <- function(x) {
rs <- x$resample
rs <- merge(rs, x$bestTune)
rs
}
foo(let_set_64)
dat <- twoClassSim(1000)
mod <- train(Class ~ ., data = dat, method = "svmRadial",
preProc = c("center", "scale"),
trControl = trainControl(method = "cv", savePredictions = "all"))
foo(mod)
head(mod$pred)
foo <- function(x) {
rs <- x$pred
rs <- merge(rs, x$bestTune)
rs
}
head(mod$pred)
foo(mod)
caret:::flatTable
foo <- function(x) {
rs <- x$pred
rs <- merge(rs, x$bestTune)
bar <- function(x) caret:::flatTable(pred = x$pred, obs = x$obs)
ddply(rs, (Resample), bar)
}
foo(mod)
library(plyr)
foo(mod)
foo <- function(x) {
rs <- x$pred
rs <- merge(rs, x$bestTune)
bar <- function(x) caret:::flatTable(pred = x$pred, obs = x$obs)
ddply(rs, .(Resample), bar)
}
foo
foo(mod)
confusionMatrix(mod)
cm_flat <- function(x) {
lev <- levels(x)
## get only best tune
names(x$bestTune) <- gsub("^\\.", "", names(x$bestTune))
resampledCM <- merge(x$bestTune, x$resampledCM)
counts <- as.matrix(resampledCM[ , grep("^\\.?cell", colnames(resampledCM))])
## normalize?
norm <- match.arg(norm, c("none", "overall", "average"))
if(norm == "none") counts <- matrix(apply(counts, 2, sum), nrow = length(lev))
else counts <- matrix(apply(counts, 2, mean), nrow = length(lev))
if(norm == "overall") counts <- counts / sum(counts) * 100
## names
rownames(counts) <- colnames(counts) <- lev
names(dimnames(counts)) <- dnn
## out
out <- list(table = as.table(counts),
norm = norm)
out
}
cm_flat(mod)
cm_flat <- function(x, norm = "overall", dnn = c("Prediction", "Reference")) {
lev <- levels(x)
## get only best tune
names(x$bestTune) <- gsub("^\\.", "", names(x$bestTune))
resampledCM <- merge(x$bestTune, x$resampledCM)
counts <- as.matrix(resampledCM[ , grep("^\\.?cell", colnames(resampledCM))])
## normalize?
norm <- match.arg(norm, c("none", "overall", "average"))
if(norm == "none") counts <- matrix(apply(counts, 2, sum), nrow = length(lev))
else counts <- matrix(apply(counts, 2, mean), nrow = length(lev))
if(norm == "overall") counts <- counts / sum(counts) * 100
## names
rownames(counts) <- colnames(counts) <- lev
names(dimnames(counts)) <- dnn
## out
out <- list(table = as.table(counts),
norm = norm)
out
}
cm_flat(mod)
names(mod)
mod$resampledCM
mod0 <- train(Class ~ ., data = dat, method = "svmRadial",
preProc = c("center", "scale"),
trControl = trainControl(method = "cv"))
mod0$pred
foo<- function(data, norm = "overall", dnn = c("Prediction", "Reference"), ...)
{
if (inherits(data, "train")) {
if(data$modelType == "Regression")
stop("confusion matrices are only valid for classification models")
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(data$control$method == "none")
return(confusionMatrix(predict(data), data$trainingData$.outcome, dnn = dnn, ...))
lev <- levels(data)
## for problems with large numbers of classes, `train` does not pre-compute the
## the resampled matrices. If the predictions have been saved, we can get them from there.
if(!is.null(data$resampledCM)) {
## get only best tune
names(data$bestTune) <- gsub("^\\.", "", names(data$bestTune))
resampledCM <- merge(data$bestTune, data$resampledCM)
} else {
if(!is.null(data$pred)) {
wrapper <- function(y) caret:::flatTable(pred  = y$pred, obs = y$obs)
resampledCM <- ddply(merge(data$pred, data$bestTune), .(Resample), function(y) caret:::flatTable(pred  = y$pred, obs = y$obs))
} else {
if(length(lev) > 50)
stop(paste("When there are 50+ classes, `train` does not automatically pre-compute the",
"resampled confusion matrices. You can get them from this function",
"using a value of `savePredictions` other than FALSE."))
}
}
} else {
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(is.null(data$resample)) {
stop("resampled confusion matrices are not availible")
} else {
if(sum(grepl("\\.cell[1-9]", names(data$resample))) > 1) {
resampledCM <- data$resample[,grepl("\\.cell[1-9]", names(data$resample))]
lev <- data$obsLevels
} else stop("resampled confusion matrices are not availible")
}
}
if(!is.null(data$control$index)) {
resampleN <- unlist(lapply(data$control$index, length))
numResamp <- length(resampleN)
resampText <- resampName(data)
} else {
resampText <- ""
numResamp <- 0
}
counts <- as.matrix(resampledCM[ , grep("^\\.?cell", colnames(resampledCM))])
## normalize?
norm <- match.arg(norm, c("none", "overall", "average"))
if(norm == "none") counts <- matrix(apply(counts, 2, sum), nrow = length(lev))
else counts <- matrix(apply(counts, 2, mean), nrow = length(lev))
if(norm == "overall") counts <- counts / sum(counts) * 100
## names
rownames(counts) <- colnames(counts) <- lev
names(dimnames(counts)) <- dnn
## out
out <- list(table = as.table(counts),
norm = norm,
B = length(data$control$index),
text = paste(resampText, "Confusion Matrix"))
class(out) <- paste0("confusionMatrix.", class(data))
out
}
foo(mod)
foo<- function(data, norm = "overall", dnn = c("Prediction", "Reference"), ...)
{
if (inherits(data, "train")) {
if(data$modelType == "Regression")
stop("confusion matrices are only valid for classification models")
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(data$control$method == "none")
return(confusionMatrix(predict(data), data$trainingData$.outcome, dnn = dnn, ...))
lev <- levels(data)
## for problems with large numbers of classes, `train` does not pre-compute the
## the resampled matrices. If the predictions have been saved, we can get them from there.
if(!is.null(data$resampledCM)) {
## get only best tune
names(data$bestTune) <- gsub("^\\.", "", names(data$bestTune))
resampledCM <- merge(data$bestTune, data$resampledCM)
} else {
if(!is.null(data$pred)) {
wrapper <- function(y) caret:::flatTable(pred  = y$pred, obs = y$obs)
resampledCM <- ddply(merge(data$pred, data$bestTune), .(Resample), function(y) caret:::flatTable(pred  = y$pred, obs = y$obs))
} else {
if(length(lev) > 50)
stop(paste("When there are 50+ classes, `train` does not automatically pre-compute the",
"resampled confusion matrices. You can get them from this function",
"using a value of `savePredictions` other than FALSE."))
}
}
} else {
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(is.null(data$resample)) {
stop("resampled confusion matrices are not availible")
} else {
if(sum(grepl("\\.cell[1-9]", names(data$resample))) > 1) {
resampledCM <- data$resample[,grepl("\\.cell[1-9]", names(data$resample))]
lev <- data$obsLevels
} else stop("resampled confusion matrices are not availible")
}
}
if(!is.null(data$control$index)) {
resampleN <- unlist(lapply(data$control$index, length))
numResamp <- length(resampleN)
resampText <- caret:::resampName(data)
} else {
resampText <- ""
numResamp <- 0
}
counts <- as.matrix(resampledCM[ , grep("^\\.?cell", colnames(resampledCM))])
## normalize?
norm <- match.arg(norm, c("none", "overall", "average"))
if(norm == "none") counts <- matrix(apply(counts, 2, sum), nrow = length(lev))
else counts <- matrix(apply(counts, 2, mean), nrow = length(lev))
if(norm == "overall") counts <- counts / sum(counts) * 100
## names
rownames(counts) <- colnames(counts) <- lev
names(dimnames(counts)) <- dnn
## out
out <- list(table = as.table(counts),
norm = norm,
B = length(data$control$index),
text = paste(resampText, "Confusion Matrix"))
class(out) <- paste0("confusionMatrix.", class(data))
out
}
foo(mod)
foo(mod0)
mod1 <- mod
mod1$resampledCM <- NULL
foo(mod1)
mod2 <- mod1
mod2$prd <- NULL
foo(mod2)
mod2
mod2$pred
mod2$pred <- NULL
foo(mod2)
names(data)
names(mod)
foo<- function(data, norm = "overall", dnn = c("Prediction", "Reference"), ...)
{
if (inherits(data, "train")) {
if(data$modelType == "Regression")
stop("confusion matrices are only valid for classification models")
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(data$control$method == "none")
return(confusionMatrix(predict(data), data$trainingData$.outcome, dnn = dnn, ...))
lev <- levels(data)
## for problems with large numbers of classes, `train` does not pre-compute the
## the resampled matrices. If the predictions have been saved, we can get them from there.
if("resampledCM" %in% names(data) && !is.null(data$resampledCM)) {
## get only best tune
names(data$bestTune) <- gsub("^\\.", "", names(data$bestTune))
resampledCM <- merge(data$bestTune, data$resampledCM)
} else {
if(!is.null(data$pred)) {
wrapper <- function(y) caret:::flatTable(pred  = y$pred, obs = y$obs)
resampledCM <- ddply(merge(data$pred, data$bestTune), .(Resample), function(y) caret:::flatTable(pred  = y$pred, obs = y$obs))
} else {
if(length(lev) > 50)
stop(paste("When there are 50+ classes, `train` does not automatically pre-compute the",
"resampled confusion matrices. You can get them from this function",
"using a value of `savePredictions` other than FALSE."))
}
}
} else {
if(data$control$method %in% c("oob", "LOOCV"))
stop("cannot compute confusion matrices for leave-one-out or out-of-bag resampling")
if(is.null(data$resample)) {
stop("resampled confusion matrices are not availible")
} else {
if(sum(grepl("\\.cell[1-9]", names(data$resample))) > 1) {
resampledCM <- data$resample[,grepl("\\.cell[1-9]", names(data$resample))]
lev <- data$obsLevels
} else stop("resampled confusion matrices are not availible")
}
}
if(!is.null(data$control$index)) {
resampleN <- unlist(lapply(data$control$index, length))
numResamp <- length(resampleN)
resampText <- caret:::resampName(data)
} else {
resampText <- ""
numResamp <- 0
}
counts <- as.matrix(resampledCM[ , grep("^\\.?cell", colnames(resampledCM))])
## normalize?
norm <- match.arg(norm, c("none", "overall", "average"))
if(norm == "none") counts <- matrix(apply(counts, 2, sum), nrow = length(lev))
else counts <- matrix(apply(counts, 2, mean), nrow = length(lev))
if(norm == "overall") counts <- counts / sum(counts) * 100
## names
rownames(counts) <- colnames(counts) <- lev
names(dimnames(counts)) <- dnn
## out
out <- list(table = as.table(counts),
norm = norm,
B = length(data$control$index),
text = paste(resampText, "Confusion Matrix"))
class(out) <- paste0("confusionMatrix.", class(data))
out
}
